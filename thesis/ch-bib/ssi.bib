@article{Brumberg2010,
  abstract = {This paper briefly reviews current silent speech methodologies for normal and disabled individuals. Current techniques utilizing electromyographic (EMG) recordings of vocal tract movements are useful for physically healthy individuals but fail for tetraplegic individuals who do not have accurate voluntary control over the speech articulators. Alternative methods utilizing EMG from other body parts (e.g., hand, arm, or facial muscles) or electroencephalography (EEG) can provide capable silent communication to severely paralyzed users, though current interfaces are extremely slow relative to normal conversation rates and require constant attention to a computer screen that provides visual feedback and/or cueing. We present a novel approach to the problem of silent speech via an intracortical microelectrode brain computer interface (BCI) to predict intended speech information directly from the activity of neurons involved in speech production. The predicted speech is synthesized and acoustically fed back to the user with a delay under 50 ms. We demonstrate that the Neurotrophic Electrode used in the BCI is capable of providing useful neural recordings for over 4 years, a necessary property for BCIs that need to remain viable over the lifespan of the user. Other design considerations include neural decoding techniques based on previous research involving BCIs for computer cursor or robotic arm control via prediction of intended movement kinematics from motor cortical signals in monkeys and humans. Initial results from a study of continuous speech production with instantaneous acoustic feedback show the BCI user was able to improve his control over an artificial speech synthesizer both within and across recording sessions. The success of this initial trial validates the potential of the intracortical microelectrode-based approach for providing a speech prosthesis that can allow much more rapid communication rates.},
  author = {Brumberg, Jonathan S and Nieto-Castanon, Alfonso and Kennedy, Philip R and Guenther, Frank H},
  doi = {10.1016/j.specom.2010.01.001},
  file = {:C$\backslash$:/Users/Petr/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Brumberg et al. - 2010 - Brain-Computer Interfaces for Speech Communication.pdf:pdf},
  issn = {0167-6393},
  journal = {Speech communication},
  keywords = {BCI,SSI,brain,computer interface,neural prosthesis,speech restoration},
  mendeley-tags = {BCI,SSI},
  month = apr,
  number = {4},
  pages = {367--379},
  pmid = {20204164},
  publisher = {Elsevier B.V.},
  title = {{Brain-Computer Interfaces for Speech Communication.}},
  url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2829990\&tool=pmcentrez\&rendertype=abstract},
  volume = {52},
  year = {2010}
}

@article{Denby2010,
  author = {Denby, Bruce and Schultz, Tanja and Honda, K. and Hueber, Thomas and Gilbert, James M. and Brumberg, J.S.},
  doi = {10.1016/j.specom.2009.08.002},
  issn = {0167-6393},
  journal = {Speech Communication},
  keywords = {cellular telephones,silent speech,speech pathologies,speech recognition,speech synthesis},
  month = apr,
  number = {4},
  pages = {270--287},
  publisher = {Elsevier B.V.},
  title = {{Silent speech interfaces}},
  url = {http://linkinghub.elsevier.com/retrieve/pii/S0167639309001307},
  volume = {52},
  year = {2010}
}

@article{Doi2010,
  author = {Doi, Hironori and Nakamura, Keigo and Toda, Tomoki and Saruwatari, Hiroshi and Shikano, Kiyohiro},
  doi = {10.1587/transinf.E93.D.2472},
  issn = {0916-8532},
  journal = {IEICE Transactions on Information and Systems},
  keywords = {eigenvoice conversion,esophageal speech,laryngectomees,speech enhancement,voice conversion},
  number = {9},
  pages = {2472--2482},
  title = {{Esophageal Speech Enhancement Based on Statistical Voice Conversion with Gaussian Mixture Models}},
  url = {http://joi.jlc.jst.go.jp/JST.JSTAGE/transinf/E93.D.2472?from=CrossRef},
  volume = {E93-D},
  year = {2010}
}

@article{Fagan2008,
  abstract = {Surgical voice restoration post-laryngectomy has a number of limitations and drawbacks. The present gold standard involves the use of a tracheo-oesophageal fistula (TOF) valve to divert air from the lungs into the throat, which vibrates, and from this, speech can be formed. Not all patients can use these valves and those who do are susceptible to complications associated with valve failure. Thus there is still a place for other voice restoration options. With advances in electronic miniaturization and portable computing power a computing-intensive solution has been investigated. Magnets were placed on the lips, teeth and tongue of a volunteer causing a change in the surrounding magnetic field when the individual mouthed words. These changes were detected by 6 dual axis magnetic sensors, which were incorporated into a pair of special glasses. The resulting signals were compared to training data recorded previously by means of a dynamic time warping algorithm using dynamic programming. When compared to a small vocabulary database, the patterns were found to be recognised with an accuracy of 97\% for words and 94\% for phonemes. On this basis we plan to develop a speech system for patients who have lost laryngeal function.},
  author = {Fagan, Michael and Ell, Stephen and Gilbert, James and Sarrazin, E and Chapman, Paul},
  doi = {10.1016/j.medengphy.2007.05.003},
  issn = {1350-4533},
  journal = {Medical engineering \& physics},
  keywords = {Alaryngeal,Algorithms,Artificial,Databases,Equipment Design,Esophageal,Factual,Humans,Laryngeal Neoplasms,Laryngeal Neoplasms: surgery,Laryngectomy,Laryngectomy: methods,Larynx,Miniaturization,Minicomputers,Reproducibility of Results,Software,Speech,Speech Recognition Software},
  month = may,
  number = {4},
  pages = {419--25},
  pmid = {17600751},
  title = {{Development of a (silent) speech recognition system for patients following laryngectomy.}},
  url = {http://www.ncbi.nlm.nih.gov/pubmed/17600751},
  volume = {30},
  year = {2008}
}

@article{Gilbert2010,
  abstract = {There are a number of situations where individuals wish to communicate verbally but are unable to use conventional means-so called 'silent speech'. These include speakers in noisy and covert situations as well as patients who have lost their voice as a result of a laryngectomy or similar procedure. This paper focuses on those who are unable to speak following a laryngectomy and assesses the possibility of speech recognition based on a magnetic implant/sensors system. Permanent magnets are placed on the tongue and lips and the changes in magnetic field resulting from movement during speech are monitored using a set of magnetic sensors. The sensor signals are compared to sets of pre-recorded templates using the dynamic time warping (DTW) method, and the best match is identified. Experimental trials are reported for subjects with intact larynx, typically using 500-1000 utterances used for speaker dependant training and testing. It is shown that recognition rates of over 90\% are achievable for vocabularies of at least 57 isolated words: sufficient to drive command-and-control applications.},
  author = {Gilbert, James M. and Rybchenko, Sergey I. and Hofe, Robin and Ell, Stephen R. and Fagan, Michael J. and Moore, Roger K. and Green, Phil D.},
  doi = {10.1016/j.medengphy.2010.08.011},
  issn = {1350-4533},
  journal = {Medical engineering \& physics},
  keywords = {Alaryngeal,Alaryngeal: instrumentation,Alaryngeal: methods,Biosensing Techniques,Biosensing Techniques: instrumentation,Biosensing Techniques: methods,Communication Aids for Disabled,Humans,Laryngectomy,Magnetics,Magnetics: instrumentation,Magnetics: methods,Phonetics,Prostheses and Implants,Speech,Speech Perception,Speech Perception: physiology,Speech Recognition Software,Vocabulary},
  month = dec,
  number = {10},
  pages = {1189--97},
  pmid = {20863739},
  publisher = {Institute of Physics and Engineering in Medicine},
  title = {{Isolated word recognition of silent speech using magnetic implants and sensors.}},
  url = {http://www.ncbi.nlm.nih.gov/pubmed/20863739},
  volume = {32},
  year = {2010}
}

@article{Hasegawa1992,
  author = {Hasegawa, T and Ohtani, K},
  journal = {Singapore ICCS/ISITA'92.' \ldots},
  pages = {617--620},
  title = {{Oral image to voice converter-image input microphone}},
  url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=255190},
  year = {1992}
}

@article{Hirahara2010,
  author = {Hirahara, Tatsuya and Otani, Makoto and Shimizu, Shota and Toda, Tomoki and Nakamura, Keigo and Nakajima, Yoshitaka and Shikano, Kiyohiro},
  doi = {10.1016/j.specom.2009.12.001},
  issn = {0167-6393},
  journal = {Speech Communication},
  keywords = {body-conducted sound,non-audible murmur,talking aids,voice conversion},
  month = apr,
  number = {4},
  pages = {301--313},
  publisher = {Elsevier B.V.},
  title = {{Silent-speech enhancement using body-conducted vocal-tract resonance signals}},
  url = {http://linkinghub.elsevier.com/retrieve/pii/S0167639309001769},
  volume = {52},
  year = {2010}
}


@article{Hofe2013,
  author = {Hofe, Robin and Ell, Stephen R. and Fagan, Michael J. and Gilbert, James M. and Green, Phil D. and Moore, Roger K. and Rybchenko, Sergey I.},
  doi = {10.1016/j.specom.2012.02.001},
  issn = {0167-6393},
  journal = {Speech Communication},
  keywords = {articulography,clinical speech technology,multi-modal speech recognition,silent speech interfaces,speech articulation},
  month = jan,
  number = {1},
  pages = {22--32},
  publisher = {Elsevier B.V.},
  title = {{Small-vocabulary speech recognition using a silent speech interface based on magnetic sensing}},
  url = {http://linkinghub.elsevier.com/retrieve/pii/S0167639312000167},
  volume = {55},
  year = {2013}
}

@article{Hueber2010,
  author = {Hueber, Thomas and Benaroya, Elie-Laurent and Chollet, G\'{e}rard and Denby, Bruce and Dreyfus, G\'{e}rard and Stone, Maureen},
  doi = {10.1016/j.specom.2009.11.004},
  issn = {0167-6393},
  journal = {Speech Communication},
  keywords = {corpus-based speech synthesis,silent speech,ultrasound,visual phone recognition},
  month = apr,
  number = {4},
  pages = {288--300},
  title = {{Development of a silent speech interface driven by ultrasound and optical images of the tongue and lips}},
  url = {http://linkinghub.elsevier.com/retrieve/pii/S0167639309001733},
  volume = {52},
  year = {2010}
}

@article{Jorgensen2010,
  author = {Jorgensen, Charles and Dusan, Sorin},
  doi = {10.1016/j.specom.2009.11.003},
  issn = {01676393},
  journal = {Speech Communication},
  keywords = {articulatory synthesis,bioelectric control,electromyography,emg,sEMG,speech recognition,speech synthesis},
  mendeley-tags = {sEMG},
  month = apr,
  number = {4},
  pages = {354--366},
  publisher = {Elsevier B.V.},
  title = {{Speech interfaces based upon surface electromyography}},
  url = {http://linkinghub.elsevier.com/retrieve/pii/S0167639309001721},
  volume = {52},
  year = {2010}
}

@article{Nakajima2003,
  author = {Nakajima, Yoshitaka and Kashioka, Hideki and Shikano, Kiyohiro and Campbell, Nick},
  issn = {1018-4074},
  pages = {2601--2604},
  title = {{Non-audible murmur recognition}},
  url = {http://library.naist.jp:12180/dspace/handle/10061/7966},
  year = {2003}
}

@article{Nakamura2012,
  annote = {Clanek obsahujici objektivni a subjektivni zhodnoceni VC techniky pro EL speech, EL-air speech, silent EL speech. Dalse je v nem podrobne popsana VC technika, konstrukce NAM mikrofonu a noveho silen EL.},
  author = {Nakamura, Keigo and Toda, Tomoki and Saruwatari, Hiroshi and Shikano, Kiyohiro},
  doi = {10.1016/j.specom.2011.07.007},
  issn = {0167-6393},
  journal = {Speech Communication},
  keywords = {airpressure sensor,electrolaryngeal speech,laryngectomee,non-audible murmur,silence excitation,speaking-aid system,speech enhancement,voice conversion},
  month = jan,
  number = {1},
  pages = {134--146},
  publisher = {Elsevier B.V.},
  title = {{Speaking-aid systems using GMM-based voice conversion for electrolaryngeal speech}},
  url = {http://linkinghub.elsevier.com/retrieve/pii/S0167639311001142},
  volume = {54},
  year = {2012}
}

@article{Ng2000,
  author = {Ng, LC and Burnett, GC},
  journal = {\ldots , and Signal Processing \ldots},
  pages = {1--4},
  title = {{Denoising of human speech using combined acoustic and EM sensor signal processing}},
  url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=861925},
  year = {2000}
}

@article{Preuss2006,
  author = {Preuss, Robert and Fabbri, Darren and Cruthirds, Daniel},
  doi = {10.1109/ICOSP.2006.345512},
  isbn = {0-7803-9736-3},
  journal = {2006 8th international Conference on Signal Processing},
  number = {3},
  publisher = {Ieee},
  title = {{Noise Robust Vocoding at 2400 bps}},
  url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4128927},
  volume = {1},
  year = {2006}
}

@article{Quatieri2006,
  author = {Quatieri, T.F. and Brady, K. and Messing, D. and Campbell, J.P. and Campbell, W.M. and  Brandstein, M.S. and Weinstein, C.J. and Tardelli, J.D. and Gatewood, P.D.},
  doi = {10.1109/TSA.2005.855838},
  issn = {1558-7916},
  journal = {IEEE Transactions on Audio, Speech and Language Processing},
  month = mar,
  number = {2},
  pages = {533--544},
  title = {{Exploiting Nonacoustic Sensors for Speech Encoding}},
  url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1597258},
  volume = {14},
  year = {2006}
}

@article{Stone1995,
  author = {Stone, Maureen and Davis, Edward P.},
  doi = {10.1121/1.413799},
  issn = {0001-4966},
  journal = {The Journal of the Acoustical Society of America},
  number = {6},
  pages = {3107--3112},
  title = {{A head and transducer support system for making ultrasound images of tongue/jaw movement}},
  url = {http://speech.umaryland.edu/AHATS/Jasa95\_Stone\_Davis.pdf http://link.aip.org/link/JASMAN/v98/i6/p3107/s1\&Agg=doi},
  volume = {98},
  year = {1995}
}

@article{Sugie1985,
  author = {Sugie, N and Tsunoda, K},
  doi = {10.1109/TBME.1985.325564},
  issn = {0018-9294},
  journal = {IEEE transactions on bio-medical engineering},
  keywords = {Biomedical Engineering,Communication Aids for Disabled,Electromyography,Humans,Mouth,Mouth: physiology,Self-Help Devices,Speech Intelligibility},
  month = jul,
  number = {7},
  pages = {485--90},
  pmid = {3160649},
  title = {{A speech prosthesis employing a speech synthesizer--vowel discrimination from perioral muscle activities and vowel production.}},
  url = {http://www.ncbi.nlm.nih.gov/pubmed/3160649},
  volume = {32},
  year = {1985}
}

@article{Toda2007,
  author = {Toda, Tomoki and Black, Alan W. and Tokuda, Keiichi},
  doi = {10.1109/TASL.2007.907344},
  issn = {1558-7916},
  journal = {IEEE Transactions on Audio, Speech and Language Processing},
  month = nov,
  number = {8},
  pages = {2222--2235},
  title = {{Voice Conversion Based on Maximum-Likelihood Estimation of Spectral Parameter Trajectory}},
  url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4317579},
  volume = {15},
  year = {2007}
}

@article{Toda2008,
  author = {Toda, Tomoki and Black, Alan W. and Tokuda, Keiichi},
  doi = {10.1016/j.specom.2007.09.001},
  issn = {0167-6393},
  journal = {Speech Communication},
  keywords = {acoustic-to-articulatory inversion mapping,articulatory-to-acoustic mapping,dynamic features,gmm,mmse},
  month = mar,
  number = {3},
  pages = {215--227},
  title = {{Statistical mapping between articulatory movements and acoustic spectrum using a Gaussian mixture model}},
  url = {http://linkinghub.elsevier.com/retrieve/pii/S0167639307001495},
  volume = {50},
  year = {2008}
}


@article{Toda2012b,
  author = {Toda, Tomoki and Nakagiri, Mikihiro and Shikano, Kiyohiro},
  doi = {10.1109/TASL.2012.2205241},
  issn = {1558-7916},
  journal = {IEEE Transactions on Audio, Speech, and Language Processing},
  month = nov,
  number = {9},
  pages = {2505--2517},
  title = {{Statistical Voice Conversion Techniques for Body-Conducted Unvoiced Speech Enhancement}},
  url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6220854},
  volume = {20},
  year = {2012}
}



@inproceedings{Denby2004,
  author = {Denby, Bruce and Stone, Maureen},
  booktitle = {2004 IEEE International Conference on Acoustics, Speech, and Signal Processing},
  doi = {10.1109/ICASSP.2004.1326078},
  isbn = {0-7803-8484-9},
  issn = {1520-6149},
  pages = {I--685--8},
  publisher = {IEEE},
  title = {{Speech synthesis from real time ultrasound images of the tongue}},
  url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1326078 http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1326078},
  volume = {1},
  year = {2004}
}

@inproceedings{Doi2011,
  author = {Doi, Hironori and Nakamura, Keigo and Toda, Tomoki and Saruwatari, Hiroshi and Shikano, Kiyohiro},
  booktitle = {2011 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  doi = {10.1109/ICASSP.2011.5947513},
  isbn = {978-1-4577-0538-0},
  issn = {1520-6149},
  month = may,
  pages = {5136--5139},
  publisher = {IEEE},
  title = {{An evaluation of alaryngeal speech enhancement methods based on voice conversion techniques}},
  url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5947513 http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5947513},
  year = {2011}
}

@inproceedings{Denby2006,
  author = {Denby, Bruce and Oussar, Yacine and Dreyfus, G. and Stone, M.},
  booktitle = {2006 IEEE International Conference on Acoustics Speed and Signal Processing Proceedings},
  doi = {10.1109/ICASSP.2006.1660033},
  isbn = {1-4244-0469-X},
  issn = {1520-6149},
  pages = {I--365--I--368},
  publisher = {IEEE},
  title = {{Prospects for a Silent Speech Interface using Ultrasound Imaging}},
  url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1660033 http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1660033},
  volume = {1},
  year = {2006}
}

@inproceedings{Deng2012,
  abstract = {Military speech communication often needs to be conducted in very high noise environments. In addition, there are scenarios, such as special-ops missions, for which it is beneficial to have covert voice communications. To enable both capabilities, we have developed the MUTE (Mouthed-speech Understanding and Transcription Engine) system, which bypasses the limitations of traditional acoustic speech communication by measuring and interpreting muscle activity of the facial and neck musculature involved in silent speech production. This article details our recent progress on automatic surface electromyography (sEMG) speech activity detection, feature parameterization, multi-task sEMG corpus development, context dependent sub-word sEMG modeling, discriminative phoneme model training, and flexible vocabulary continuous sEMG silent speech recognition. Our current system achieved recognition accuracy at developable levels for a pre-defined special ops task. We further propose research directions in adaptive sEMG feature parameterization and data driven decision question generation for context-dependent sEMG phoneme modeling.},
  author = {Deng, Yunbin and Colby, Glen and Heaton, James T. and Meltzner, Geoffrey S.},
  booktitle = {MILCOM 2012 - 2012 IEEE Military Communications Conference},
  doi = {10.1109/MILCOM.2012.6415781},
  isbn = {978-1-4673-1731-3},
  keywords = {sEMG},
  mendeley-tags = {sEMG},
  month = oct,
  pages = {1--6},
  publisher = {IEEE},
  title = {{Signal processing advances for the MUTE sEMG-based silent speech recognition system}},
  url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=6415781 http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6415781},
  year = {2012}
}

@inproceedings{DaSalla2009,
  address = {New York, New York, USA},
  author = {DaSalla, Charles S and Kambara, Hiroyuki and Koike, Yasuharu and Sato, Makoto},
  booktitle = {Proceedings of the 3rd International Convention on Rehabilitation Engineering \& Assistive Technology - ICREATE '09},
  doi = {10.1145/1592700.1592731},
  isbn = {9781605587929},
  keywords = {BCI,CSP,EEG,imagery,spatial filter,speech,vowel},
  pages = {27:1--27:4},
  publisher = {ACM Press},
  series = {i-CREATe '09},
  title = {{Spatial filtering and single-trial classification of EEG during vowel speech imagery}},
  url = {http://doi.acm.org/10.1145/1592700.1592731 http://portal.acm.org/citation. cfm?doid=1592700.1592731},
  year = {2009}
}

@inproceedings{Hofe2011,
  author = {Hofe, Robin and Ell, SR and Fagan, MJ and Gilbert, JM},
  booktitle = {INTERSPEECH},
  keywords = {[Electronic Manuscript]},
  number = {August},
  pages = {3009--3012},
  title = {{Speech Synthesis Parameter Generation for the Assistive Silent Speech Interface MVOCA.}},
  url = {https://wiki.inf.ed.ac.uk/twiki/pub/CSTR/Speak11To12/IS110030.PDF},
  year = {2011}
}

@inproceedings{Hueber2007,
  abstract = {The article compares two approaches to the description of ultrasound vocal tract images for application in a "silent speech interface," one based on tongue contour modeling, and a second, global coding approach in which images are projected onto a feature space of Eigentongues. A curvature-based lip profile feature extraction method is also presented. Extracted visual features are input to a neural network which learns the relation between the vocal tract configuration and line spectrum frequencies (LSF) contained in a one-hour speech corpus. An examination of the quality of LSFs derived from the two approaches demonstrates that the Eigemongues approach has a more efficient implementation and provides superior results based on a normalized mean squared error criterion},
  author = {Hueber, Thomas and Aversano, G. and Chollet, G\'{e}rard and Denby, Bruce and Dreyfus, G\'{e}rard and Oussar, Yacine and Roussel, P. and Stone, Maureen},
  booktitle = {2007 IEEE International Conference on Acoustics, Speech and Signal Processing - ICASSP '07},
  doi = {10.1109/ICASSP.2007.366140},
  isbn = {1-4244-0727-3},
  number = {c},
  pages = {1245--1248},
  publisher = {IEEE},
  title = {{Eigentongue Feature Extraction for an Ultrasound-Based Silent Speech Interface}},
  url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4217312 http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4217312},
  year = {2007}
}

@inproceedings{Hueber2011,
  author = {Hueber, Thomas and Benaroya, Elie-laurent},
  booktitle = {Interspeech},
  isbn = {978-1-61839-270-1},
  issn = {1990-9772},
  number = {August},
  pages = {593--596},
  title = {{Statistical Mapping Between Articulatory and Acoustic Data for an Ultrasound-Based Silent Speech Interface.}},
  url = {http://gipsa-www.ampere.inpg.fr/~thomas.hueber/mes\_documents/hueber\_etal\_interspeech2011.pdf},
  year = {2011}
}

@inproceedings{Hueber2012,
  address = {Portland, USA},
  author = {Hueber, Thomas and Bailly, G\'{e}rard and Denby, Bruce},
  booktitle = {Interspeech},
  pages = {2--5},
  title = {{Continuous Articulatory-to-Acoustic Mapping using Phone-based Trajectory HMM for a Silent Speech Interface}},
  url = {http://hal.archives-ouvertes.fr/hal-00741682/},
  year = {2012}
}

@inproceedings{Moriguchi2013,
  author = {Moriguchi, Takuto and Toda, Tomoki and Sano, Motoaki and Sato, Hiroshi and Neubig, Graham and Sakti, Sakriani and Nakamura, Satoshi},
  booktitle = {Interspeech},
  keywords = {[Electronic Manuscript]},
  number = {August},
  pages = {3072--3076},
  title = {{A Digital Signal Processor Implementation of Silent / Electrolaryngeal Speech Enhancement based on Real-Time Statistical Voice Conversion}},
  year = {2013}
}


@inproceedings{Nakajima2005,
  author = {Nakajima, Yoshitaka and Kashioka, Hideki and Shikano, Kiyohiro and Campbell, Nick},
  booktitle = {Interspeech},
  pages = {389--392},
  title = {{Remodeling of the sensor for non-audible murmur (NAM)}},
  url = {http://library.naist.jp/dspace/handle/10061/8137},
  year = {2005}
}

@inproceedings{Toda2012a,
  author = {Toda, Tomoki},
  booktitle = {2012 ICME International Conference on Complex Medical Engineering (CME)},
  doi = {10.1109/ICCME.2012.6275604},
  isbn = {978-1-4673-1618-7},
  issn = {1990-9772},
  number = {August},
  pages = {623--628},
  publisher = {IEEE},
  title = {{Statistical approaches to enhancement of body-conducted speech detected with non-audible murmur microphone}},
  url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6275604},
  year = {2012}
}

@inproceedings{Toda2012c,
  author = {Toda, Tomoki and Muramatsu, Takashi and Banno, Hideki},
  booktitle = {Interspeech},
  number = {4},
  pages = {4--7},
  title = {{Implementation of Computationally Efficient Real-Time Voice Conversion.}},
  year = {2012}
}

@inproceedings{Tokuda2000,
  author = {Tokuda, Keiichi and Yoshimura, Takayoshi and Masuko, Takashi and Kobayashi, T. and Kitamura, T.},
  booktitle = {2000 IEEE International Conference on Acoustics, Speech, and Signal Processing. Proceedings},
  doi = {10.1109/ICASSP.2000.861820},
  isbn = {0-7803-6293-4},
  number = {l},
  pages = {1315--1318},
  publisher = {IEEE},
  title = {{Speech parameter generation algorithms for HMM-based speech synthesis}},
  url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=861820},
  volume = {3},
  year = {2000}
}

@inproceedings{Yamamoto2012,
  author = {Yamamoto, Kenzo and Toda, Tomoki and Doi, Hironori and Saruwatari, Hiroshi and Shikano, Kiyohiro},
  booktitle = {2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  doi = {10.1109/ICASSP.2012.6287949},
  isbn = {978-1-4673-0046-9},
  issn = {1520-6149},
  month = mar,
  pages = {4497--4500},
  publisher = {IEEE},
  title = {{Statistical approach to voice quality control in esophageal speech enhancement}},
  url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=6287949 http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6287949},
  year = {2012}
}

@misc{Fagan2006,
  title={Generation of data from speech or voiceless mouthed speech},
  author={Fagan, Michael and Chapman, Paul and Gilbert, James and Ell, Stephen and others},
  year={2006},
  month=jul # "~21",
  note={WO Patent 2,006,075,179}
}

@misc{Nakamura1988,
  title={Method of recognizing speech using a lip image},
  author={Nakamura, Hiroyuki},
  year={1988},
  month=sep # "~6",
  publisher={Google Patents},
  note={US Patent 4,769,845}
}

@book{Hrazdira2008,
  author={Hrazdira, Ivo},
  title={\'{U}vod do ultrasonografie v ot\'{a}zk\'{a}ch a odpov\v{e}d\'{i}ch},
  year={2008},
  address={Brno},
  pages = {36},
}

@book{Muller2007,
  address = {Berlin, Heidelberg},
  author = {M\"{u}ller, C},
  doi = {10.1007/978-3-540-74200-5},
  editor = {M\"{u}ller, Christian},
  isbn = {978-3-540-74186-2},
  issn = {0302-9743},
  publisher = {Springer Berlin Heidelberg},
  series = {Lecture Notes in Computer Science},
  title = {{Speaker Classification I}},
  url = {http://link.springer.com/content/pdf/10.1007/978-3-540-74122-0.pdf http://link.springer. com/10.1007/978-3-540-74200-5},
  volume = {4343},
  year = {2007}
}

@book{Psutka2006,
  author = {Psutka, Josef and M\"{u}ller, Lud\v{e}k and Matou\v{s}ek, Jindřich and Radov\'{a}, Vlasta},
  title = {Mluv\'{i}me s po\v{c}\'{i}ta\v{c}em \v{c}esky},
  year = {2006},
  publisher = {Academia},
  address = {Prague},
  pages = {752},
  ISBN = {80-200-1309-1},
  url = {http://www.kky.zcu.cz/en/publications/PsutkaJ_2006_Mluvimes},
}

@INPROCEEDINGS{Psutka2007,
 author = {Psutka Josef V. and \v{S}m\'{i}dl, L. and Pra\v{z}\'{a}k, A.},
 title = {Searching for a robust MFCC-based parameterization for ASR application},
 year = {2007},
 publisher = {INSTICC PRESS},
 journal = {SIGMAP 2007},
 address = {Lisabon},
 pages = {196-199},
 ISBN = {978-989-8111-13-5}
}

@inproceedings{Radova2000,
  author = {Radov\'{a}, Vlasta and Psutka, Josef},
  year = {2000},
  month = {01},
  pages = {732-735},
  title = {UWB\_S01 corpus - a czech read-speech corpus}
}

@inproceedings{Stolcke2002,
  title={SRILM-an extensible language modeling toolkit},
  author={Stolcke, Andreas},
  booktitle={Seventh international conference on spoken language processing},
  year={2002}
}

@inproceedings{Prazak2008,
  title={Efficient combination of N-gram language models and recognition grammars in real-time LVCSR decoder},
  author={Pra\v{z}\'{a}k, Ale\v{s} and Ircing, Pavel and \v{S}vec, Jan and Psutka, Josef},
  booktitle={2008 9th International Conference on Signal Processing},
  pages={587--591},
  year={2008},
  organization={IEEE}
}

@INPROCEEDINGS{Kaldi2011,
         author = {Povey, Daniel and Ghoshal, Arnab and Boulianne, Gilles and Burget, Lukas and Glembek, Ondrej and Goel, Nagendra and Hannemann, Mirko and Motlicek, Petr and Qian, Yanmin and Schwarz, Petr and Silovsky, Jan and Stemmer, Georg and Vesely, Karel},
       keywords = {ASR, Automatic Speech Recognition, GMM, HTK, SGMM},
          month = dec,
          title = {The Kaldi Speech Recognition Toolkit},
      booktitle = {IEEE 2011 Workshop on Automatic Speech Recognition and Understanding},
           year = {2011},
      publisher = {IEEE Signal Processing Society},
       location = {Hilton Waikoloa Village, Big Island, Hawaii, US},
           note = {IEEE Catalog No.: CFP11SRW-USB},
}

@article{Hannun2014,
  author    = {Awni Y. Hannun and
               Carl Case and
               Jared Casper and
               Bryan Catanzaro and
               Greg Diamos and
               Erich Elsen and
               Ryan Prenger and
               Sanjeev Satheesh and
               Shubho Sengupta and
               Adam Coates and
               Andrew Y. Ng},
  title     = {Deep Speech: Scaling up end-to-end speech recognition},
  journal   = {CoRR},
  volume    = {abs/1412.5567},
  year      = {2014},
  url       = {http://arxiv.org/abs/1412.5567},
  archivePrefix = {arXiv},
  eprint    = {1412.5567},
  timestamp = {Mon, 13 Aug 2018 16:48:07 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/HannunCCCDEPSSCN14},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@InProceedings{Alumae2014,
  author={Alum\"{a}e, Tanel},
  title={Neural network phone duration model for speech recognition},
  booktitle={Interspeech 2014},
  address={Singapore},
  year=2014
}

@inproceedings{Hadian2017,
  title={Phone Duration Modeling for LVCSR Using Neural Networks.},
  author={Hadian, Hossein and Povey, Daniel and Sameti, Hossein and Khudanpur, Sanjeev},
  booktitle={INTERSPEECH},
  pages={518--522},
  year={2017}
}

@inproceedings{Yoshimura1998,
  title={Duration modeling for HMM-based speech synthesis},
  author={Yoshimura, Takayoshi and Tokuda, Keiichi and Masuko, Takashi and Kobayashi, Takao and Kitamura, Tadashi},
  booktitle={Fifth International Conference on Spoken Language Processing},
  year={1998}
}

@ARTICLE{Waibel1989,
author={A. {Waibel} and T. {Hanazawa} and G. {Hinton} and K. {Shikano} and K. J. {Lang}},
journal={IEEE Transactions on Acoustics, Speech, and Signal Processing},
title={Phoneme recognition using time-delay neural networks},
year={1989},
volume={37},
number={3},
pages={328-339},
keywords={neural nets;speech recognition;speech;time-delay neural networks;phoneme recognition;three-layer;computing units;nonlinear decision surfaces;error backpropagation;temporal shifts;hidden Markov models;testing tokens;Neural networks;Speech recognition;Hidden Markov models;Computer science;Psychology;Character recognition;Computer networks;Backpropagation;Acoustic testing;Loudspeakers},
doi={10.1109/29.21701},
ISSN={0096-3518},
month={March},}

@inproceedings{Peddinti2015,
  title={A time delay neural network architecture for efficient modeling of long temporal contexts},
  author={Peddinti, Vijayaditya and Povey, Daniel and Khudanpur, Sanjeev},
  booktitle={Sixteenth Annual Conference of the International Speech Communication Association},
  year={2015}
}
