% !TEX root = ../thesis.tex
\section{Model akcentující protažení dat}
\label{chap:realisation:durationmodels}

Augmentace dat (viz část \ref{chap:realisation:augmentation}) ukázala, že ztracenou informaci EL řeči je částečné možné nahradit protažením inkriminovaných fonémů.
Experimenty s~reálně protaženými daty (viz část \ref{chap:realisation:augmentation:real}) navíc prokázaly schopnost člověla toto protažení realizovat.
Dalším krokem je tedy úprava modelu tak, aby tuto změnu co možná nejvíce reflektoval.

% Z principu fungování a nejpoužívanější topologie HMM modelu (viz \ref{chap:asr:acoustic:HMM})
S ohledem na princip fungování HMM a jeho topologie je délka fonému modelována pomocí přechodových pravděpodobností, které vedou na funkce geometrické distribuce pravděpodobnosti \cite{Rabiner1989}.
Bohužel skutečná podoba těchto distribucí odpovídá spíše gamma nebo logaritmicko-normálnímu rozdělení \cite{Alumae2014}.
Správné modelování délky může být realizováno úpravou přechodových funkcí v~HMM nebo změnou topologie modelu.
Další možností je vytvoření speciálního modelu pracujícího s~délkou jednotlivých fonémů (duration model) a reskórováním výstupních N-best hypotéz či celé rozpoznávací mřížky \cite{Alumae2014} \cite{Anastasakos1995}
\cite{Gadde2000}.

Přestože se první uvažovaný způsob jeví jako vhodnější, tak všechny dosavadní publikované výsledky ukazují významné zvýšení výpočetní náročnosti dekódování a komplexity modelu \cite{Rabiner1989} \cite{Pylkkonen2004} \cite{Russell1985}. Tento přístup je však často používán u HMM syntézy řeči, viz \cite{Yoshimura1998}.

\subsection{Princip explicitních duration modelů}
\label{chap:realisation:durationmodels:model}

Další možností je vytvoření explicitního modelu pracujícího s~délkou fonémů. Aby bylo možno takový model využít, je často potřeba problém rozpoznávání přeformulovat na úlohu nalezení nejlepší sekvence slov $W^{*}$ a jim odpovídajících délek $D^{*}$ \cite{Alumae2014}. Za předpokladu, že je dána sekvence slov $W$ a vektory pozorování $\boldsymbol{O}$ lze považovat za nezávislé na délkách $D$, je možné rovnici \ref{eq:asr:decoding} upravit jako

\begin{align}
  W^{*}, D^{*} &= \argmax_{W, D} P\left(W, D| \boldsymbol{O}\right) \nonumber  \\
          &= \argmax_{W, D} P\left(\boldsymbol{O}, D| W\right)P\left(W\right) \nonumber  \\
          &= \argmax_{W, D} P\left(\boldsymbol{O}|W\right)P\left(D|W\right)P\left(W\right).
  \label{eq:realisation:durationmodels:assumtion}
\end{align}

\noindent Úkolem duration modelu je tedy odhadnout pravděpodobnosti $P\left(D|W\right)$, přičemž délku $D$ je možné dekomponovat na $m$ délek jednotlivých fonémů $d_{i}$

\begin{equation}
  P\left(D | W\right) = P\left(d_{1}, \dots, d_{m}|W\right).
  \label{eq:realisation:durationmodels:decomposition}
\end{equation}

\noindent Tuto pravděpodobnost je dále možné upravit pomocí tzv. chain pravidla do tvaru

\begin{align}
  P\left(d_{1}, \dots, d_{m} | W\right) &= \prod_{i=1}^{m} P\left(d_{i} | d_{1}, \dots, d_{i-1}, W\right) \nonumber \\
        &\approx \prod_{i=1}^{m} P\left(d_{i} | d_{i-n-1}, \dots, d_{i-1}, W\right).
  \label{eq:realisation:durationmodels:chain}
\end{align}

\noindent Model tedy odhaduje pravděpodobnost $P\left(D|W\right)$ na základě délek $n$ předchozích fonémů a předpokládaného slova $W$. Některé duration modely navíc pracují i s~tempem řeči \cite{Pylkkonen2004}, tento efekt je však u modelu využívajícího vztah \ref{eq:realisation:durationmodels:chain} zohledněn prostřednictvím délek $n$ předchozích fonémů. Ve skutečnosti je vhodné vytvořit model, který bere v~potaz nejen délky předchozích fonémů, ale i příznakové vektory těchto fonémů \cite{Alumae2014}. Zohlednění délek předchozích fonémů v~závislosti je provedeno prostřednictvím pravděpodobnosti  $P\left(d_{i}|x_{i}\right)$, kde $x_{i}$ představuje příznakový vektor obsahující délky $n$ předchozích fonémů, jejich vektory pozorování a případně další hodnoty. K~ odhadu této pravděpodobnosti se jako vhodné ukázaly neuronové sítě \cite{Alumae2014}, \cite{Hadian2017}.

Na odhad $P\left(d_{i}|x_{i}\right)$ je možné nahlížet ze dvou pohledů. V~prvním případě je cílem odhadnout parametry pravděpobnostní distribuce pomocí conditional density estimation network (CDEN) \cite{Alumae2014}. V~tomto případě se předpokládá, že délky fonémů odpovídají určitému pravděpodobnostnímu rozdělení, nejčastěji logaritmicko-normálnímu. Konkrétní hodnota pravděpodobnosti je pak stanovena s~využitím příslušného vztahu pro výpočet hustoty pravděpodobnosti.

Druhou možností je stejně jako v~případě HMM-DNN akustického modelu odhad pseudo-pravděpodobností za pomocí NN mající jako poslední vrstvu tzv. softmax vrstvu. Tento přístup nevnáší do modelu žádné předpoklady o podobě pravděpodobnostního rozdělení. Experimenty v~\cite{Hadian2017} ukazují, že tento přístup je vhodnější\footnote{Při vytváření duration modelu byly otestovány oba přístupy a i naše experimenty ukazují, že NN se softmax vrstvou poskytuje lepší výsledky, protože u EL řeči CDEN model přinesl zanedbatelné zlepšení a v~některých případech dokonce reskórování způsobilo zhoršení výsledků.}.

\subsection{Duration model se softmax vrstvou}
\label{chap:realisation:durationmodels:nn:softmax}

Neuronová síť mající na svém výstupu softmax vrstvu (viz rovnice \ref{eq:asr:acoustic:dnn:asr:softmax}) určuje diskrétní pseudo-pravděpodobnosti $m$ tříd. V~případě duration modelu, se jako vhodné jeví reprezentovat jednotlivé třídy jako počet mikrosegmentů ($d=1,2,3,\dots$), které odpovídají danému fonému. Čistě teoreticky může být těchto mikrosegmentů nekonečné množství, síť však na svém výstupu potřebuje konečný počet tříd (počet neuronů ve výstupní vrstvě). Jako vhodné řešení tohoto problému se ukázalo zvolit maximální délky fonému $D$. Pro všechny s~délkou $d \geq D$ platí, že $p\left(d\right) = p\left(D\right)$. \cite{Hadian2017} Volba $D$ závisí na konkrétní doméně a je vhodné ji určit experimentem.

Úlohou modelu je predikovat sekvenci délek na základě sekvence fonémů. To implikuje možnost použití levého kontextu ($L$) i pravého kontextu ($R$) fonému $i$. Do vstupního vektoru sítě ale mohou přijít pouze délky fonémů $L$ kontextu  nebo $R$ kontextu. Pokud by totiž byly použity oba kontexty, tak by délka fonému $i$ závisela na délce fonému $i+1$. Zároveň by ale délka fonému $i+1$ závisela na délce fonému $i$. Tím pádem by došlo ke kruhové závislosti, kterou není možné vyřešit. Jestliže je zvolen levý ($L$) kontext pro délky, pak příznakový vektor obsahuje následující položky:

\begin{itemize}
  \item Pro každý foném kontextu $-L \leq i \leq R$ je použito kódování 1 z n (1 pro správný foném, 0 pro ostatní, angl. one-hot encoding). Celková dimenze kontextu je tak $N_{p} \times \left(L + R + 1\right)$, kde $N_{p}$ je počet fonémů ve slovníku.
  \item Druhou množinu příznaků reprezentují otázky použité u fonetických rozhodovacích stromů (viz část \ref{chap:construction:results:reduction}). U těchto otázek je opět použito one-hot encoding. Dimenze těchto příznaků je $N_{q} \times \left(L + R + 1\right)$, kde $N_{q}$ odpovídá celkovému počtu otázek.
  \item Poslední skupinu příznaků představují délky fonémů L kontextu na pozicích $-L \leq i < 0$. Celková dimenze je $L$. Neuronová síť nejlépe pracuje s~hodnotami v~intervalu $\left(0, 1\right)$. Jako vhodné se ukázalo normalizovat hodnotu délky $d=1, 2, \dots, D$ pomocí sigmoid funkce

  \begin{equation}
    d^{\prime} = \frac{2}{1 + e^{-0,01d}} - 1,
    \label{eq:realisation:durationmodels:nn:normalization}
  \end{equation}

  \noindent která transformuje hodnoty do požadovaného intervalu $\left(0, 1\right)$ \cite{Alumae2014}. Pokud není kontext  k~dispozici (krajní případy), tak $d = 0$.
\end{itemize}

\noindent Celková dimenze výsledného příznakového vektoru je pak $I = \left(L + R + 1\right) \ast \left(N_{p} + N_{q}\right) + L$.

Samotné reskórování výstupní mřížky je realizováno přidáním $\log p\left(d_{i}| x_{i}\right)$, kde $x_{i}$ je vstupní příznakový vektor duration modelu,  k~hodnotám získaným z akustického a jazykového modelu. Mřížka je mezivýsledek, ze kterého je následně vydekódován výstup ASR systému. Samotné duration skóre je navíc přenásobeno konstantou získanou z development sady v~průběhu trénování modelu tak, aby jeho řád odpovídal hodnotám z ostatních modelů. \cite{Hadian2017} Stejně jako v~případě jazykového modelu je i zde tzv. váha duration modelu, která umožňuje měnit vliv tohoto modelu.

\subsection{Dosažené výsledky}
\label{chap:realisation:durationmodels:nn:softmax:results}

Stejně jako v~případě augmentace dat (viz \ref{chap:realisation:augmentation:audio}) je potřeba  k~natrénování duration modelu kvalitní zarovnání. Jednou z hlavních částí příznakového vektoru modelu je totiž délka L kontextu modelu. K získání co možná nejpřesnějšího zarovnání je použit nejlepší TDNN model natrénovaný na uměle protažených datech\footnote{Natrénování TDNN modelu pomocí reálně protažených dat nebylo vhodné, protože nebylo  k~dispozici dostatečné množství reálně protažených dat.}, viz tab. \ref{tab:realisation:augmentation:influence:tdnn}.

Samotný duration model (popsaný v~předchozí části \ref{chap:realisation:durationmodels:nn:softmax}) je typu feedforward.  Počet skrytých vrstev sítě se odvíjí od konkrétní řešené domény, ale standardně se uvažují $2$ případně $3$, viz \cite{Hadian2017}. Velikost těchto skrytých vrstev je volena jako násobek dimenze příznakového vektoru, v~tomto případě byl zvolena hodnota $3I$. Aktivační funkce je typu RELU. Velikost výstupní vrstvy odpovídá maximálnímu počtu mikrosegmentů $D$, v~\cite{Hadian2017} bylo dosaženo nejlepších výsledků s~$D=50$. K vytvoření duration modelu posloužil framework Kaldi. Ten představuje obecný framework pro vytváření HMM a DNN řečových modelů.

Ověření funkčnosti duration modelu je provedeno na $2x$ uměle protažených datech\footnote{Hodnota $2x$ je zvolena, protože se nejvíce blíží reálně protaženým datům.}. Kontextuální okénko má hodnotu $\left(L, R\right) = \left(3, 3\right)$, $N_{p} = 42$ a $N_{q} = 6$. Velikost vstupního vektoru $I = 339$. Model má $2$ skryté vrstvy o velikosti $1017$ neuronů. Výstupní vrstva typu softmax má dimenzi $D=50$. Model je trénován a otestován pomocí stejné trénovací a testovací sady jako modely v~části \ref{chap:realisation:augmentation:audio}. Jazykový model je fonémový zerogramový. Tento model dosáhl $Acc_{p} = 88,54~\%$, což představuje zlepšení o~$0,83~\%$ absolutně a $7,24~\%$ relativně oproti TDNN $2x$ modelu pro uměle vytvořenou množinu trénovacích dat ($Acc_{p} = 87,71~\%$). Duration model tedy relativně významně zlepšuje přesnost modelu. Na reálně protažených datech pak tento model dosáhl přesnosti $Acc_{p} = 85,68~\%$ (původní TDNN $2x$ model dosáhl $Acc_{p} = 84,51~\%$). Pokud vstupem duration modelu byla neprotažená data, tak přesnost modelu byla pouze $Acc_{p} = 80,73~\%$. Z analýzy chyb pak plyne, že v~takovém případě významně přibylo chyb u vybraných neznělých fonémů. Tento výsledek, ale přesně kopíruje očekávání, protože je model natrénován na protaženou podobu.

Mezi hyperparametry modelu patří zejména velikost $L$ a $R$ kontextu, počet vrstev sítě a maximální délka $D$. Zejména hodnota maximální délka $D$ teoreticky poskytuje největší možnost pro zlepšení výsledků modelu, protože hodnota $D=50$ byla zvolena na základě experimentů provedených v~\cite{Hadian2017}, kde se však pracovalo se standardní neprotaženou řečí. Tab. \ref{tab:realisation:duration:duration} ukazuje vliv maximální délky na přesnost modelu. Speciální je hodnota $D=189$, která je určena automaticky na základě zarovnání před samotným trénováním. Model s~$D=189$ zároveň dosáhl nejvyšší přesnosti $Acc_{p} = 88,58~\%$, což představuje drobné zlepšení oproti původnímu modelu s~$D = 50$.

\begin{table}[htpb]
  \centering
  \def\arraystretch{1.5}
  \pgfplotstabletypeset[
    col sep=semicolon,
    string type,
    columns/header/.style={
      column name={},
      column type={l},
      string replace={accp}{$Acc_{p}\ [\%]$}
    },
    columns/50/.style={column name={50}, column type={r}},
    columns/100/.style={column name={100}, column type={r}},
    columns/150/.style={column name={150}, column type={r}},
    columns/189/.style={column name={189}, column type={r}},
    columns/200/.style={column name={200}, column type={r}},
    every head row/.style={
      before row={\toprule & \multicolumn{5}{c}{D} \\},
      after row={\midrule}
    },
    every last row/.style={after row={\bottomrule}}
  ]{./ch6-realisation/tabs/01-duration_value.csv}
  \caption{Vliv maximální délky na přesnosti modelu.}
  \label{tab:realisation:duration:duration}
\end{table}

Dalším hyperparametrem, který může ovlivnit kvalitu modelu, je počet vrstev neuronové sítě. V~tab. \ref{tab:realisation:duration:layers} jsou vypsány výsledky jednotlivých modelů. Varianta \textit{1H} představuje model s~$1$ skrytou vrstvou, \textit{2H} model s~$2$ skrytými vrstvami a \textit{3H} s~$3$~skrytými vrstvami. Speciálním případem jsou modely obsahující bottleneck vrstvu (\textit{2H (bottleneck)} a \textit{3H (bottleneck)}). Ty místo poslední skryté vrstvy o velikosti $3I$ obsahují vrstvu s~pouze $10$ neurony. Tato vrstva by měla pomoci v~zobecňování \cite{Hadian2017}. Z dosažených výsledků je patrné, že velikost sítě není úplně zásadním parametrem. Rozdíl mezí přesností sítě s~$2$ a $3$ vrstvami je minimální. Přínos bottleneck vrstvy, oproti výsledkům prezentovaným v~\cite{Hadian2017}, je také spíše minimální. Nicméně obecně se dá říci, že tato vrstva má pozitivní dopad na přesnost.

\begin{table}[htpb]
  \centering
  \def\arraystretch{1.5}
  \pgfplotstabletypeset[
    col sep=semicolon,
    string type,
    columns/layers/.style={
      column name={},
      column type={l},
      string replace={accp}{$Acc_{p}\ [\%]$}
    },
    columns/1H/.style={column name={1H}, column type={r}},
    columns/2H/.style={column name={2H}, column type={r}},
    columns/3H/.style={column name={3H}, column type={r}},
    columns/2Hb/.style={column name={2H (bottleneck)}, column type={r}},
    columns/3Hb/.style={column name={3H (bottleneck)}, column type={r}},
    every head row/.style={
      before row={\toprule & \multicolumn{5}{c}{Model} \\},
      after row={
        % \cmidrule{2-6}
        \midrule
      }
    },
    every last row/.style={after row={\bottomrule}},
  ]{./ch6-realisation/tabs/02-layers.csv}
  \caption[Vliv spočtu krytých vrstev na přesnost.]{Vliv počtu skrytých vrstev na přesnosti modelu ($D = 189$\footnotemark).}
  \label{tab:realisation:duration:layers}
\end{table}

\footnotetext{V průběhu určování nejlepších kombinace hyperparametrů byly otestovány všechny kombinace velikosti sítě a maximální délky $D$. Nejlepších výsledků dosahovaly modely s~$D=189$.}

Posledním hyperparametrem, který může mít vliv na přesnost modelu, je velikost $L$ a $R$ kontextu. Z tab. \ref{tab:realisation:duration:context:symetric} a tab. \ref{tab:realisation:duration:context:asymetric} vyplývá, že nejlepších výsledků dosahují modely, které mají délku kontext $L + R = 6$. Úplně nejlepšího výsledku pak dosáhl model mající symetrický kontext, ale oproti modelům s~asymetrickým kontextem je rozdíl spíše zanedbatelný.

\begin{table}[htpb]
  \centering
  \def\arraystretch{1.5}
  \pgfplotstabletypeset[
    col sep=semicolon,
    string type,
    columns/context/.style={
      column name={},
      column type={l},
      string replace={accp}{$Acc_{p}\ [\%]$}
    },
    columns/0/.style={column name={(0, 0)}, column type={r}},
    columns/1/.style={column name={(1, 1)}, column type={r}},
    columns/2/.style={column name={(2, 2)}, column type={r}},
    columns/3/.style={column name={(3, 3)}, column type={r}},
    columns/4/.style={column name={(4, 4)}, column type={r}},
    every head row/.style={
      before row={\toprule & \multicolumn{5}{c}{Kontext \textit{(L, R)}} \\},
      after row={
        % \cmidrule(r){1-1}
        % \cmidrule{2-6}
        \midrule
      }
    },
    every last row/.style={after row={\bottomrule}},
  ]{./ch6-realisation/tabs/03-context.csv}
  \caption{Porovnání vlivu velikosti symetrického kontextu.}
  \label{tab:realisation:duration:context:symetric}
\end{table}

\begin{table}[htpb]
  \centering
  \def\arraystretch{1.5}
  \pgfplotstabletypeset[
    col sep=semicolon,
    string type,
    columns/context/.style={
      column name={},
      column type={l},
      string replace={accp}{$Acc_{p}\ [\%]$}
    },
    columns/5/.style={column name={(5, 1)}, column type={r}},
    columns/4/.style={column name={(4, 2)}, column type={r}},
    columns/3/.style={column name={(3, 3)}, column type={r}},
    columns/2/.style={column name={(2, 4)}, column type={r}},
    columns/1/.style={column name={(1, 5)}, column type={r}},
    every head row/.style={
      before row={\toprule & \multicolumn{5}{c}{Kontext \textit{(L, R)}} \\},
      after row={
        % \cmidrule(r){1-1}
        % \cmidrule{2-6}
        \midrule
      }
    },
    every last row/.style={after row={\bottomrule}},
  ]{./ch6-realisation/tabs/04-context.csv}
  \caption{Vliv levého a pravého kontextu v~případě, že celková délka $L + R = 6$.}
  \label{tab:realisation:duration:context:asymetric}
\end{table}

Nejlepšího výsledku tedy dosahuje model mající $D = 189$, $2$ skryté vrstvy, kde poslední skrytá vrstva má pouze $10$ neuronů a $L + R = 6$. Výsledky však ukazují, že duration model není významně citlivý na změnu parametrů. V~případě rozpoznávání reálně protažených dat, dosáhl model přesnosti $Acc_{p} = 85,93~\%$. Pokud se trénovací sada modelu rozšířila o část reálně protažených dat ($10~\%$ a $25~\%$ vět) a natrénoval a otestoval se nový model (pomocí zbytku reálně protažených dat), tak výsledná přesnost dosáhla hodnoty $Acc_{p} = 87,02~\%$. Hodnoty přesnosti však nejsou úplně porovnatelné, protože testovací sada není identická, nicméně lze vyvozovat závěr, že pokud by byl model natrénován z dostatečného množství reálně protažených dat, tak by se jeho výsledky blížily výsledkům modelu na uměle protažených datech.


\subsection{Aktualizace výsledků porovnání}
\label{chap:realisation:duration:comparison}

V části \ref{chap:realisation:listening} a \ref{chap:realisation:augmentation:comparison} jsou prezentovány výsledky srovnání schopností člověka a stroje. V~případě člověka jsou zdrojem dva poslechové testy, které prověřily schopnost posluchače nejprve určit význam izolovaných slov, a následně od sebe rozeznat dvě akusticky velmi podobná slova. V~případě stroje jsou použity celkem $3$ ASR experimenty \uv{one-mil}, \uv{reduced} a \uv{bigrams}. V~tab. \ref{tab:realisation:duration:comparison} jsou pak předchozí výsledky doplněny o hodnoty dosažené duration modelem jehož parametry odpovídají nejlepšímu modelu z předchozí části \ref{chap:realisation:durationmodels:nn:softmax}.

Stejně jako v~předchozích experimentech je u~\uv{one-mil} experimentu použit zerogramový jazykový model s~1 milionem slov, \uv{reduced} obsahuje pouze slova obsažená v~poslechovém testu. V~případě \uv{bigrams} je pro každou položku generován speciální LM obsahující 4 kombinace slov. Použití duration modelu nepřineslo významné zlepšení výsledků \textit{augmented} modelu. Tento výsledek, ale není překvapivý, protože \textit{augmented} model dosahuje teoreticky maximálních možných hodnot. Největšího zlepšení dosáhl duration model v~případě \uv{one-mil} experimentu. Zde došlo ke zlepšení o~$1,42~\%$ absolutně, což je o~$10,42~\%$ relativně. Rozhodně se jedná o významné zlepšení.

\begin{table}[htpb]
  \centering
  \def\arraystretch{1.5}
  \pgfplotstabletypeset[
    col sep=semicolon,
    string type,
    columns/type/.style={column name=, column type={l}},
    columns/onemil/.style={column name={one-mil}, column type={r}},
    columns/reduced/.style={column name=reduced, column type={r}},
    columns/bigrams/.style={column name=bigrams, column type={r}},
    every head row/.style={
      after row={
        % \cmidrule(lr){1-1}
        % \cmidrule(lr){2-4}
        \midrule
      },
      before row={\toprule & \multicolumn{3}{c}{$Acc_{p}\ [\%]$} \\}
    },
    every last row/.style={
      after row={\bottomrule},
      before row={\midrule}
    },
  ]{./ch6-realisation/tabs/05-comparison.csv}
  \caption{Aktualizované porovnání dosažených výsledků člověka a stroje.}
  \label{tab:realisation:duration:comparison}
\end{table}

Použití reskóringu pomocí duration modelu ještě zlepšuje výsledky TDNN modelu natrénovaného na protažených datech. Oba modely navíc dokáží pracovat i s~řečníkem reálně protaženými daty, což umožňuje i reálné použití těchto modelů. Hlavní nedostatek aktuální implementace reskóringu pomocí duration modelu spočívá v~tom, že se jedná o offline přístup. Promluvy jsou nejprve zpracovány pomocí TDNN modelu a až následně jsou kompletní výstupy modelu reskórovány pomocí duration modelu. Změna modelu a principu reskórování tak, aby byl schopen pracovat i v~online režimu, je otázkou budoucího výzkumu, ale principiálně tomu nic nebrání.
